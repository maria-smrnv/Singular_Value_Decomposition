{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79bac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680fc237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.double)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b24b96bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:06<00:00, 1.64MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 241kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.59MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.55MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561ffa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard model without SVD\n",
    "class Standart_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Standart_model, self).__init__()\n",
    "        self.dense1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fde8f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD grad method for SVD_dense\n",
    "class SVD_dense(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=None):\n",
    "        super(SVD_dense, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.rank = rank if rank is not None else min(in_features, out_features)\n",
    "\n",
    "        # Initialize learnable parameters\n",
    "        self.U = nn.Parameter(torch.randn(out_features, self.rank))\n",
    "        self.raw_S = nn.Parameter(torch.randn(self.rank))\n",
    "        self.Vh = nn.Parameter(torch.randn(self.rank, in_features))\n",
    "        \n",
    "        # Initialize orthogonal matrix\n",
    "        with torch.no_grad():\n",
    "            Q_u, _ = torch.linalg.qr(self.U.data)\n",
    "            self.U.data.copy_(Q_u)\n",
    "            Q_v, _ = torch.linalg.qr(self.Vh.T.data)\n",
    "            self.Vh.data.copy_(Q_v.T)\n",
    "    \n",
    "    def get_S(self):\n",
    "        return nn.functional.softplus(self.raw_S)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        S = self.get_S()\n",
    "        weight = (self.U * S.unsqueeze(0)) @ self.Vh\n",
    "        return x @ weight.T\n",
    "    \n",
    "    def prune(self, threshold_ratio=0.1):\n",
    "        S = self.get_S().detach()\n",
    "        max_s = torch.max(S)\n",
    "        threshold = max_s * threshold_ratio\n",
    "        \n",
    "        mask = S > threshold\n",
    "        new_rank = torch.sum(mask).item()\n",
    "        \n",
    "        if new_rank == 0:\n",
    "            new_rank = 1\n",
    "            mask[0] = True\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.U.data = self.U.data[:, mask]\n",
    "            self.raw_S.data = self.raw_S.data[mask]\n",
    "            self.Vh.data = self.Vh.data[mask, :]\n",
    "        \n",
    "        self.rank = new_rank\n",
    "        return new_rank\n",
    "    \n",
    "    def orthogonality_regularization(self):\n",
    "        I_r = torch.eye(self.rank, device=self.U.device)\n",
    "        U_loss = torch.norm(self.U.T @ self.U - I_r, p='fro')**2\n",
    "        V_loss = torch.norm(self.Vh @ self.Vh.T - I_r, p='fro')**2\n",
    "        return U_loss + V_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec83f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD_model with SVD\n",
    "class SVD_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, rank_ratio=0.5):\n",
    "        super(SVD_Model, self).__init__()\n",
    "        self.svd1 = SVD_dense(input_size, hidden_size, int(hidden_size * rank_ratio))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.svd2 = SVD_dense(hidden_size, output_size, int(output_size * rank_ratio))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.svd1(x))\n",
    "        x = self.svd2(x)\n",
    "        return x\n",
    "    \n",
    "    def ortho_loss(self):\n",
    "        return self.svd1.orthogonality_regularization() + self.svd2.orthogonality_regularization()\n",
    "    \n",
    "    def prune(self, threshold_ratio=0.1):\n",
    "        rank1 = self.svd1.prune(threshold_ratio)\n",
    "        rank2 = self.svd2.prune(threshold_ratio)\n",
    "        return rank1, rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d0e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "def train_model(model, train_loader, test_loader, epochs, ortho_weight=0.1, is_svd=False):\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses, test_accuracies = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            if is_svd:\n",
    "                ortho_loss = model.ortho_loss()\n",
    "                loss += ortho_weight * ortho_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(total_loss / len(train_loader))\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}: Loss = {train_losses[-1]:.4f}, Accuracy = {accuracy:.2f}%')\n",
    "    \n",
    "    return train_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcbfd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0b8edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаем стандартную модель\n",
      "Epoch 0: Loss = 0.3997, Accuracy = 92.86%\n",
      "Epoch 10: Loss = 0.0437, Accuracy = 97.45%\n",
      "Epoch 20: Loss = 0.0191, Accuracy = 97.65%\n",
      "Epoch 30: Loss = 0.0125, Accuracy = 97.83%\n",
      "Epoch 40: Loss = 0.0085, Accuracy = 97.99%\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    print(\"Обучаем стандартную модель\")\n",
    "    standard_model = Standart_model(input_size, hidden_size, output_size)\n",
    "    standard_loss, standard_acc = train_model(standard_model, train_loader, test_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160cb6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standart_model(\n",
      "  (dense1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dense2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Общее количество параметров: 203,530\n"
     ]
    }
   ],
   "source": [
    "standard_model_cpu = standard_model.cpu()\n",
    "\n",
    "print(standard_model)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = count_parameters(standard_model)\n",
    "print(f\"Общее количество параметров: {total_params:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c474f475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаем SVD модель\n",
      "Epoch 0: Loss = 0.8425, Accuracy = 88.09%\n",
      "Epoch 10: Loss = 0.1273, Accuracy = 95.72%\n",
      "Epoch 20: Loss = 0.0849, Accuracy = 96.96%\n",
      "Epoch 30: Loss = 0.0765, Accuracy = 96.94%\n",
      "Epoch 40: Loss = 0.0768, Accuracy = 97.26%\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    print(\"Обучаем SVD модель\")\n",
    "    svd_model = SVD_Model(input_size, hidden_size, output_size)\n",
    "    svd_loss, svd_acc = train_model(svd_model, train_loader, test_loader, epochs, is_svd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38dae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD_Model(\n",
      "  (svd1): SVD_dense()\n",
      "  (relu): ReLU()\n",
      "  (svd2): SVD_dense()\n",
      ")\n",
      "Общее количество параметров: 134,583\n"
     ]
    }
   ],
   "source": [
    "print(svd_model)\n",
    "\n",
    "total_params_svd = count_parameters(svd_model)\n",
    "print(f\"Общее количество параметров: {total_params_svd:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0b49af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Применяем прунинг\n",
      "Новые ранги после прунинга: fc1=70, fc2=5\n",
      "Дообучаем после прунинга\n",
      "Epoch 0: Loss = 0.0698, Accuracy = 96.90%\n",
      "Epoch 10: Loss = 0.0618, Accuracy = 96.82%\n",
      "Epoch 20: Loss = 0.0661, Accuracy = 97.16%\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0): \n",
    "    print(\"Применяем прунинг\")\n",
    "    rank1, rank2 = svd_model.prune(threshold_ratio=0.1)\n",
    "    print(f\"Новые ранги после прунинга: fc1={rank1}, fc2={rank2}\")\n",
    "\n",
    "    print(\"Дообучаем после прунинга\")\n",
    "    svd_pruned_loss, svd_pruned_acc = train_model(svd_model, train_loader, test_loader, epochs//2, is_svd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7daca77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.31\n"
     ]
    }
   ],
   "source": [
    "print(svd_pruned_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e920cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD_Model(\n",
      "  (svd1): SVD_dense()\n",
      "  (relu): ReLU()\n",
      "  (svd2): SVD_dense()\n",
      ")\n",
      "Общее количество параметров: 74,205\n"
     ]
    }
   ],
   "source": [
    "print(svd_model)\n",
    "\n",
    "total_params_svd_2 = count_parameters(svd_model)\n",
    "print(f\"Общее количество параметров: {total_params_svd_2:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
